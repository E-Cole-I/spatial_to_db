{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rds\n",
    "import fiona\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "from shapely.geometry import shape, Polygon, MultiPolygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geom_finder(file_item, centroid_list):\n",
    "\n",
    "    # Nab coordinates from the shapefile\n",
    "    gtype = file_item['geometry']['type']\n",
    "    \n",
    "    # Check type of geometry (Important for handling of mixed geometries)\n",
    "    if gtype == 'Polygon':\n",
    "        # Grab coordinates from the object\n",
    "        coords = file_item['geometry']['coordinates'][0]\n",
    "        \n",
    "        # Convert them to a shapely object\n",
    "        shp_geom = Polygon(coords)\n",
    "        \n",
    "        # Get the WKT coordinates from the geometry (Suitable for redshift/postgres)\n",
    "        wkt_geom = shp_geom.wkt\n",
    "        \n",
    "        # Grab centroid to run contains query for testing. \n",
    "        poly_centroid = shp_geom.centroid.wkt\n",
    "        centroid_list.append(poly_centroid)\n",
    "    \n",
    "    # If the geometry type is multipolygon\n",
    "    elif gtype == 'MultiPolygon':\n",
    "        \n",
    "        # Coordinates for a multipolygon can be converted without the 0 index\n",
    "        coords = file_item['geometry']['coordinates']\n",
    "        gtype = file_item['geometry']['type']\n",
    "        \n",
    "        # Shapely Geometry type\n",
    "        wkt_geom = MultiPolygon(shape(file_item['geometry'])).wkt\n",
    " \n",
    "        \n",
    "    else:\n",
    "        # Catch any weird/not appropriate geometry types\n",
    "        print(\"Not a Polygon or a Multipolygon\", \"\\nGeometry Type\", gtype)\n",
    "        pass\n",
    "    \n",
    "    return wkt_geom   \n",
    "\n",
    "# This is for testing purposes......\n",
    "\n",
    "def test_shp(table_name, centroid_list):\n",
    "    try:\n",
    "        # Test 10 random centroid points to make sure polygons have valid shapes\n",
    "        for i in range(10):\n",
    "            point = random.choice(centroid_list)\n",
    "\n",
    "            query_select = \"\"\" select * from {} where ST_Contains({}.geom, ST_GeomFromText('{}'))\n",
    "\n",
    "                            \"\"\".format(table_name, table_name, point)\n",
    "            test_query = rds.output_query(query_select)\n",
    "\n",
    "        print('Success!!! Found all 10 points..')\n",
    "    except:\n",
    "        print('The selected point did not return any polygons... Something may be wrong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating..... tl_2019_us_county table\n",
      "Done with 100 records....\n",
      "Done with 200 records....\n",
      "Done with 300 records....\n",
      "Done with 400 records....\n",
      "Done with 500 records....\n",
      "Done with 600 records....\n",
      "Done with 700 records....\n",
      "Done with 800 records....\n",
      "Done with 900 records....\n",
      "Done with 1000 records....\n",
      "Done with 1100 records....\n",
      "Done with 1200 records....\n",
      "Done with 1300 records....\n",
      "Done with 1400 records....\n",
      "Done with 1500 records....\n",
      "Done with 1600 records....\n",
      "Done with 1700 records....\n",
      "Done with 1800 records....\n",
      "Done with 1900 records....\n",
      "Done with 2000 records....\n",
      "Done with 2100 records....\n",
      "Done with 2200 records....\n",
      "Done with 2300 records....\n",
      "Done with 2400 records....\n",
      "Done with 2500 records....\n",
      "Done with 2600 records....\n",
      "Done with 2700 records....\n",
      "Done with 2800 records....\n",
      "Done with 2900 records....\n",
      "Done with 3000 records....\n",
      "Done with 3100 records....\n",
      "Done with 3200 records....\n",
      "Done Creating the Table......\n",
      "Shape to Table Time:  18.542275925477345 minutes\n",
      "Starting Testing...\n",
      "Success!!! Found all 10 points..\n",
      "Shape to Table Time With Testing:  18.550527366002402 minutes\n"
     ]
    }
   ],
   "source": [
    "def shp_to_db(file_name, del_table='N', table_name = 'default'):\n",
    "    \"\"\"\n",
    "    This script is meant to take a shapefile, create a db table in postgres/redshift, and populate it. \n",
    "    \n",
    "    Right now, this script only works with polygon/multipolygon shapefiles... This will change soon.\n",
    "    \"\"\"\n",
    "            \n",
    "        \n",
    "    start_time = time.time()    \n",
    "        \n",
    "    # Open the file\n",
    "    file = fiona.open(file_name)\n",
    "    \n",
    "    #--------------------START OF TABLE CREATION----------------------------------\n",
    "    \n",
    "    \n",
    "    # Table name grabbed from the file if the argument is the default\n",
    "    if table_name == 'default':\n",
    "        table_name = file_name.split('/')[-1].split('.')[-2]\n",
    "    print('Creating.....', table_name, \"table\")\n",
    "    \n",
    "    if del_table == 'Y':\n",
    "        # This mostly for testing, but it gives the user the option to delete an existing table.\n",
    "        try:\n",
    "            delete_query = 'DROP TABLE {};'.format(table_name)\n",
    "            rds.input_query(delete_query)\n",
    "\n",
    "        except:\n",
    "            print('Could Not Delete Table')\n",
    "            \n",
    "            # Stop code if the table couldn't be deleted and the user selected Y\n",
    "            return\n",
    "    \n",
    "    \n",
    "    # Get the table columns and data types\n",
    "\n",
    "    # Gets the keys of the fiona object which is essentially a dictionary\n",
    "    column_list = list(file[0]['properties'].keys())\n",
    "\n",
    "\n",
    "    # Start building the query to create the table\n",
    "    base_query = \"CREATE TABLE \" + table_name + \" ( \"\n",
    "    idx = 0\n",
    "    \n",
    "    # Loop through the column list to add new coluns to query string..\n",
    "    for i in column_list:\n",
    "        col = i\n",
    "        col_type = type(file[0]['properties'][i])\n",
    "        col_type_pgsql = None\n",
    "\n",
    "        # Checking the column datatype to adjust it to a postgres type. I'm just doing basic conversions, but a more detailed approach is pretty simple. \n",
    "        if col_type == str:\n",
    "            col_type_pgsql = 'TEXT'\n",
    "\n",
    "        elif col_type == int:\n",
    "            col_type_pgsql = 'BIGINT'\n",
    "            \n",
    "        elif col_type == float:\n",
    "            col_type_pgsql = 'DOUBLE PRECISION'\n",
    "\n",
    "        # Catch all bin... \n",
    "        else:\n",
    "            col_type_pgsql = 'TEXT'\n",
    "\n",
    "        base_query += col + \" \" + col_type_pgsql + \", \"\n",
    "\n",
    "\n",
    "    # Add the final bracket and colon on the query string\n",
    "    base_query += \"geom geometry);\"\n",
    "\n",
    "\n",
    "    # Execute the query \n",
    "    rds.input_query(base_query)\n",
    "    \n",
    "    #--------------------END OF TABLE CREATION----------------------------------\n",
    "    \n",
    "    # Build the insert query so the data can be transfered\n",
    "    centroid_list = []\n",
    "    \n",
    "    # Refactor the code - Trying to make this fast using mogrify\n",
    "    arg_list = []\n",
    "    \n",
    "    \n",
    "    for j in file:\n",
    "        \n",
    "        # Add to the arg_list\n",
    "        add_arg = []\n",
    "        \n",
    "        # Status Update for Larger Files. \n",
    "        idx+=1 \n",
    "        if idx%100 == 0:\n",
    "            print('Done with', idx,'records....')\n",
    "            \n",
    "            \n",
    "        # Insert query string\n",
    "        insert_query = \"INSERT INTO \" + table_name + \" ( \"\n",
    "        inputs = \"\"\n",
    "\n",
    "\n",
    "        # Loop over the shapefile columns and add them to the string\n",
    "        for i in column_list:\n",
    "            insert_query += i + \", \"\n",
    "            \n",
    "            # Add arguments to add_arg\n",
    "            add_arg.append(str(j['properties'][i]))\n",
    "            \n",
    "            \n",
    "            # Creating the input/values part of the insert query\n",
    "            input_string = str(j['properties'][i]).replace(\"'\",\"\")\n",
    "            inputs += \"'\" + input_string + \"', \"\n",
    "\n",
    "        # Finish with the correct version of the geometry transform (No Coordinate system.)\n",
    "        insert_query += ' geom) values ( ' + inputs + \"ST_GeomFromText('{}'));\"\n",
    "\n",
    "        # Get the wkt geometry \n",
    "        geom_col = geom_finder(j, centroid_list)\n",
    "        \n",
    "        # Add geometry as an argument\n",
    "        add_arg.append(geom_col)\n",
    "        \n",
    "        # add_arg list to arg_list as a tuple\n",
    "        arg_list.append(tuple(add_arg))\n",
    "        \n",
    "        \n",
    "        # Add the geometry to the string through string formatting\n",
    "        insert_query = insert_query.format(geom_col)\n",
    "\n",
    "\n",
    "        # Run the insert query\n",
    "        rds.input_query(insert_query)\n",
    "        \n",
    "    print('Done Creating the Table......')\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(\"Shape to Table Time: \", (end_time-start_time)/60, \"minutes\")\n",
    "    \n",
    "    print('Starting Testing...')\n",
    "    test_shp(table_name, centroid_list)\n",
    "    end_time = time.time()\n",
    "    print(\"Shape to Table Time With Testing: \", (end_time-start_time)/60, \"minutes\")\n",
    "    \n",
    "    return arg_list\n",
    "\n",
    "# TEST - County shapefile\n",
    "file_name = '../Data/tl_2019_us_county.shp'\n",
    "arguments = shp_to_db(file_name, 'Y')    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
